import { speechApi } from './apiFactory'

export const speechApiService = {
  // è¯­éŸ³è½¬æ–‡å­—
  speechToText(audioData, options = {}) {
    const formData = new FormData()
    
    // å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡
    if (audioData instanceof File) {
      formData.append('audio', audioData)
    } else if (audioData instanceof Blob) {
      // å¦‚æœæ˜¯Blobå¯¹è±¡
      formData.append('audio', audioData, 'audio.wav')
    } else {
      // å¦‚æœæ˜¯base64å­—ç¬¦ä¸²
      formData.append('audio_data', audioData)
      formData.append('format', options.format || 'wav')
    }
    
    // æ·»åŠ å…¶ä»–å‚æ•°
    if (options.language) {
      formData.append('language', options.language)
    }
    if (options.sampleRate) {
      formData.append('sample_rate', options.sampleRate)
    }
    
    return speechApi.post('/api/speech/stt', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    })
  },

  // æ–‡å­—è½¬è¯­éŸ³
  textToSpeech(data) {
    return speechApi.post('/api/speech/tts', {
      text: data.text,
      character_id: data.characterId,
      voice_settings: data.voiceSettings || {
        rate: 1.0,
        pitch: 1.0,
        volume: 0.8
      },
      format: data.format || 'mp3'
    })
  },

  // ä¸Šä¼ è¯­éŸ³æ–‡ä»¶
  uploadAudio(file) {
    const formData = new FormData()
    formData.append('audio', file)
    
    return speechApi.post('/api/speech/upload', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    })
  },

  // è·å–è¯­éŸ³æ–‡ä»¶
  getAudio(id) {
    return speechApi.get(`/api/speech/audio/${id}`, {
      responseType: 'blob'
    })
  }
}

// å®Œæ•´çš„VoiceRecorderç±»ï¼Œæ”¯æŒè¯­éŸ³è½¬æ–‡å­—
export class VoiceRecorder {
  constructor() {
    this.isRecording = false
    this.mediaRecorder = null
    this.stream = null
    this.audioChunks = []
    this.onTranscriptCallback = null
  }

  async startRecording() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      this.mediaRecorder = new MediaRecorder(this.stream)
      this.audioChunks = []
      this.isRecording = true
      
      // æ”¶é›†éŸ³é¢‘æ•°æ®
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data)
        }
      }
      
      // å½•éŸ³ç»“æŸæ—¶å¤„ç†
      this.mediaRecorder.onstop = async () => {
        await this.processRecording()
      }
      
      this.mediaRecorder.start()
      console.log('ğŸ¤ å¼€å§‹å½•éŸ³...')
      return true
    } catch (error) {
      console.error('å½•éŸ³å¯åŠ¨å¤±è´¥:', error)
      return false
    }
  }

  stopRecording() {
    if (this.mediaRecorder && this.isRecording) {
      console.log('ğŸ¤ åœæ­¢å½•éŸ³...')
      this.mediaRecorder.stop()
      this.isRecording = false
      if (this.stream) {
        this.stream.getTracks().forEach(track => track.stop())
      }
    }
  }

  async processRecording() {
    try {
      if (this.audioChunks.length === 0) {
        console.warn('æ²¡æœ‰å½•éŸ³æ•°æ®')
        return
      }

      // åˆ›å»ºéŸ³é¢‘Blob
      const audioBlob = new Blob(this.audioChunks, { type: 'audio/wav' })
      console.log('ğŸ¤ å½•éŸ³å®Œæˆï¼Œå¤§å°:', (audioBlob.size / 1024).toFixed(2), 'KB')

      // è°ƒç”¨è¯­éŸ³è½¬æ–‡å­—API
      if (this.onTranscriptCallback) {
        try {
          console.log('ğŸ”„ æ­£åœ¨è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—...')
          const response = await speechApiService.speechToText(audioBlob, {
            language: 'zh-CN',
            format: 'wav'
          })
          
          if (response && response.data && response.data.text) {
            console.log('âœ… è¯­éŸ³è½¬æ–‡å­—æˆåŠŸ:', response.data.text)
            this.onTranscriptCallback(response.data.text)
          } else {
            console.warn('è¯­éŸ³è½¬æ–‡å­—è¿”å›ç©ºç»“æœ')
            this.onTranscriptCallback('')
          }
        } catch (error) {
          console.error('âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
          // é™çº§æ–¹æ¡ˆï¼šæ˜¾ç¤ºæç¤ºä¿¡æ¯
          this.onTranscriptCallback('[è¯­éŸ³è½¬æ–‡å­—å¤±è´¥ï¼Œè¯·é‡è¯•]')
        }
      }
    } catch (error) {
      console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error)
    }
  }

  // è®¾ç½®è½¬å½•å›è°ƒå‡½æ•°
  setTranscriptCallback(callback) {
    this.onTranscriptCallback = callback
  }
}

// ç®€åŒ–çš„VoicePlayerç±»
export class VoicePlayer {
  constructor() {
    this.audio = new Audio()
    this.isPlaying = false
  }

  async play(audioUrl) {
    try {
      this.audio.src = audioUrl
      await this.audio.play()
      this.isPlaying = true
      return true
    } catch (error) {
      console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
      return false
    }
  }

  stop() {
    this.audio.pause()
    this.audio.currentTime = 0
    this.isPlaying = false
  }
}

// ä¿æŒå‘åå…¼å®¹
export const speechApi_old = speechApiService
export default speechApiService 