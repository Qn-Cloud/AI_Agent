package logic

import (
	"context"
	"encoding/base64"
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"

	"ai-roleplay/services/speech/api/internal/svc"
	"ai-roleplay/services/speech/api/internal/types"

	asr "github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/asr/v20190614"
	"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common"
	"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common/errors"
	"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common/profile"
	"github.com/zeromicro/go-zero/core/logx"
)

type SpeechToTextLogic struct {
	logx.Logger
	ctx    context.Context
	svcCtx *svc.ServiceContext
	r      *http.Request
}

func NewSpeechToTextLogic(ctx context.Context, svcCtx *svc.ServiceContext, r *http.Request) *SpeechToTextLogic {
	return &SpeechToTextLogic{
		Logger: logx.WithContext(ctx),
		ctx:    ctx,
		svcCtx: svcCtx,
		r:      r,
	}
}

func (l *SpeechToTextLogic) SpeechToText(req *types.SpeechToTextRequest) (resp *types.SpeechToTextResponse, err error) {
	l.Logger.Infof("æ”¶åˆ°è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚: Language=%s, Format=%s", req.Language, req.Format)

	// è·å–éŸ³é¢‘æ•°æ®
	audioData, audioSize, err := l.extractAudioData(req)
	if err != nil {
		l.Logger.Errorf("æå–éŸ³é¢‘æ•°æ®å¤±è´¥: %v", err)
		return &types.SpeechToTextResponse{}, err
	}

	if audioSize == 0 {
		l.Logger.Error("éŸ³é¢‘æ•°æ®ä¸ºç©º")
		return &types.SpeechToTextResponse{}, fmt.Errorf("éŸ³é¢‘æ•°æ®ä¸ºç©º")
	}

	l.Logger.Infof("éŸ³é¢‘æ•°æ®å¤§å°: %d bytes", audioSize)

	// æ ¹æ®é…ç½®é€‰æ‹©è¯­éŸ³è¯†åˆ«æœåŠ¡
	provider := l.svcCtx.Config.Speech.ASR.Provider
	l.Logger.Infof("ğŸ” å½“å‰é…ç½®çš„ASRæä¾›å•†: %s", provider)

	// æ£€æŸ¥è…¾è®¯äº‘é…ç½®
	tencentConfig := l.svcCtx.Config.External.Tencent
	if len(tencentConfig.SecretID) > 10 && len(tencentConfig.SecretKey) > 10 {
		l.Logger.Infof("ğŸ” è…¾è®¯äº‘é…ç½®: SecretID=%s..., SecretKey=%s...",
			tencentConfig.SecretID[:10], tencentConfig.SecretKey[:10])
	} else {
		l.Logger.Infof("ğŸ” è…¾è®¯äº‘é…ç½®: SecretID=%s, SecretKey=%s",
			tencentConfig.SecretID, tencentConfig.SecretKey)
	}

	var recognizedText string
	var confidence float64
	var duration float64

	switch provider {
	case "tencent":
		recognizedText, confidence, duration, err = l.performTencentASR(audioData, req)
		if err != nil {
			l.Logger.Errorf("è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹Ÿå®ç°: %v", err)
			recognizedText, confidence, duration = l.performMockRecognition(audioData, req)
		}
	case "baidu":
		l.Logger.Info("ç™¾åº¦AIè¯­éŸ³è¯†åˆ«æš‚æœªå®ç°ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
		recognizedText, confidence, duration = l.performMockRecognition(audioData, req)
	case "mock":
		fallthrough
	default:
		recognizedText, confidence, duration = l.performMockRecognition(audioData, req)
	}

	// æ„é€ å“åº”
	resp = &types.SpeechToTextResponse{
		Text:       recognizedText,
		Confidence: confidence,
		Duration:   duration,
	}

	l.Logger.Infof("è¯­éŸ³è¯†åˆ«æˆåŠŸ: æ–‡ä»¶å¤§å°=%d bytes, æ–‡æœ¬=%s", audioSize, recognizedText)
	return resp, nil
}

// æå–éŸ³é¢‘æ•°æ®
func (l *SpeechToTextLogic) extractAudioData(req *types.SpeechToTextRequest) ([]byte, int64, error) {
	// ä¼˜å…ˆå¤„ç†multipart/form-dataæ–‡ä»¶ä¸Šä¼ 
	if strings.Contains(l.r.Header.Get("Content-Type"), "multipart/form-data") {
		file, header, err := l.r.FormFile("audio")
		if err != nil {
			return nil, 0, fmt.Errorf("è·å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: %v", err)
		}
		defer file.Close()

		audioData, err := io.ReadAll(file)
		if err != nil {
			return nil, 0, fmt.Errorf("è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: %v", err)
		}

		l.Logger.Infof("ä»multipart formè·å–éŸ³é¢‘æ–‡ä»¶: %s, å¤§å°: %d bytes", header.Filename, len(audioData))
		return audioData, header.Size, nil
	}

	// å¦‚æœæ²¡æœ‰multipartæ•°æ®ï¼Œå°è¯•ä»base64å­—æ®µè·å–
	if req.AudioData != "" {
		audioData, err := base64.StdEncoding.DecodeString(req.AudioData)
		if err != nil {
			return nil, 0, fmt.Errorf("base64è§£ç å¤±è´¥: %v", err)
		}
		l.Logger.Infof("ä»base64è·å–éŸ³é¢‘æ•°æ®, å¤§å°: %d bytes", len(audioData))
		return audioData, int64(len(audioData)), nil
	}

	return nil, 0, fmt.Errorf("æœªæ‰¾åˆ°éŸ³é¢‘æ•°æ®")
}

// è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«
func (l *SpeechToTextLogic) performTencentASR(audioData []byte, req *types.SpeechToTextRequest) (string, float64, float64, error) {
	l.Logger.Info("ä½¿ç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«...")

	// æ£€æŸ¥è…¾è®¯äº‘é…ç½®
	tencentConfig := l.svcCtx.Config.External.Tencent
	if tencentConfig.SecretID == "" || tencentConfig.SecretKey == "" {
		return "", 0, 0, fmt.Errorf("è…¾è®¯äº‘é…ç½®ä¸å®Œæ•´")
	}

	// è¿™é‡Œå¯ä»¥é›†æˆè…¾è®¯äº‘è¯­éŸ³è¯†åˆ«SDK
	// ç”±äºéœ€è¦å¼•å…¥è…¾è®¯äº‘SDKï¼Œæš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
	credential := common.NewCredential(
		tencentConfig.SecretID,
		tencentConfig.SecretKey,
	)
	cpf := profile.NewClientProfile()
	cpf.HttpProfile.Endpoint = "asr.tencentcloudapi.com"
	// å®ä¾‹åŒ–è¦è¯·æ±‚äº§å“çš„clientå¯¹è±¡,clientProfileæ˜¯å¯é€‰çš„
	client, _ := asr.NewClient(credential, "", cpf)

	// å®ä¾‹åŒ–ä¸€ä¸ªè¯·æ±‚å¯¹è±¡,æ¯ä¸ªæ¥å£éƒ½ä¼šå¯¹åº”ä¸€ä¸ªrequestå¯¹è±¡
	request := asr.NewSentenceRecognitionRequest()

	// è¿”å›çš„respæ˜¯ä¸€ä¸ªSentenceRecognitionResponseçš„å®ä¾‹ï¼Œä¸è¯·æ±‚å¯¹è±¡å¯¹åº”
	response, err := client.SentenceRecognition(request)
	if _, ok := err.(*errors.TencentCloudSDKError); ok {
		fmt.Printf("An API error has returned: %s", err)
		return "", 0, 0, err
	}
	if err != nil {
		panic(err)
	}
	// è¾“å‡ºjsonæ ¼å¼çš„å­—ç¬¦ä¸²å›åŒ…
	fmt.Printf("%s", response.ToJsonString())

	l.Logger.Info("è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«SDKé›†æˆå¾…å®ç°ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")

	// æ¨¡æ‹Ÿè…¾è®¯äº‘çš„å“åº”æ ¼å¼
	recognizedText := "è¿™æ˜¯è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«çš„æ¨¡æ‹Ÿç»“æœ"
	confidence := 0.92

	// è®¡ç®—éŸ³é¢‘æ—¶é•¿
	sampleRate := float64(req.SampleRate)
	if sampleRate == 0 {
		sampleRate = 16000
	}
	duration := float64(len(audioData)) / (sampleRate * 2)
	if duration < 0.5 {
		duration = 0.5
	}

	l.Logger.Infof("è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«å®Œæˆ: æ–‡æœ¬=%s, ç½®ä¿¡åº¦=%.2f, æ—¶é•¿=%.2fs", recognizedText, confidence, duration)
	return recognizedText, confidence, duration, nil
}

// æ”¹è¿›çš„æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«
func (l *SpeechToTextLogic) performMockRecognition(audioData []byte, req *types.SpeechToTextRequest) (string, float64, float64) {
	l.Logger.Info("ä½¿ç”¨æ”¹è¿›çš„æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«...")
	time.Sleep(200 * time.Millisecond) // æ¨¡æ‹Ÿè¯†åˆ«æ—¶é—´

	// æ›´æ™ºèƒ½çš„æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
	var recognizedText string
	var confidence float64

	// æ ¹æ®éŸ³é¢‘å¤§å°å’Œä¸€äº›ç®€å•ç‰¹å¾ç»™å‡ºæ¨¡æ‹Ÿç»“æœ
	audioSizeKB := len(audioData) / 1024

	// è®¡ç®—éŸ³é¢‘çš„ç®€å•ç‰¹å¾ï¼ˆæ¨¡æ‹ŸéŸ³é¢‘åˆ†æï¼‰
	audioSum := 0
	maxLen := 1000
	if len(audioData) < maxLen {
		maxLen = len(audioData)
	}
	for i := 0; i < maxLen; i++ {
		audioSum += int(audioData[i])
	}
	audioFeature := audioSum % 10

	// æ ¹æ®éŸ³é¢‘å¤§å°å’Œç‰¹å¾é€‰æ‹©ä¸åŒçš„å›ç­”
	shortTexts := []string{"ä½ å¥½", "å–‚", "æ˜¯çš„", "å¥½çš„", "è°¢è°¢", "ä¸æ˜¯", "å¯ä»¥", "æ²¡æœ‰"}
	mediumTexts := []string{"ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ", "æˆ‘æƒ³äº†è§£ä¸€ä¸‹ç›¸å…³ä¿¡æ¯", "è¿™ä¸ªé—®é¢˜æ¯”è¾ƒå¤æ‚", "è®©æˆ‘æƒ³æƒ³æ€ä¹ˆå›ç­”"}
	longTexts := []string{
		"ä½ å¥½ï¼Œæˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
		"è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„é—®é¢˜ï¼Œè®©æˆ‘è¯¦ç»†ä¸ºæ‚¨è§£ç­”ä¸€ä¸‹ç›¸å…³çš„å†…å®¹å’ŒèƒŒæ™¯",
		"æ ¹æ®æ‚¨çš„æè¿°ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªæƒ…å†µéœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ æ‰èƒ½ç»™å‡ºå‡†ç¡®çš„å»ºè®®",
	}

	if audioSizeKB < 8 {
		// çŸ­éŸ³é¢‘ï¼Œå¯èƒ½æ˜¯ç®€å•è¯æ±‡
		recognizedText = shortTexts[audioFeature%len(shortTexts)]
		confidence = 0.82 + float64(audioFeature%3)*0.05
	} else if audioSizeKB < 25 {
		// ä¸­ç­‰éŸ³é¢‘ï¼Œå¯èƒ½æ˜¯çŸ­å¥
		recognizedText = mediumTexts[audioFeature%len(mediumTexts)]
		confidence = 0.87 + float64(audioFeature%4)*0.03
	} else {
		// é•¿éŸ³é¢‘ï¼Œå¯èƒ½æ˜¯é•¿å¥
		recognizedText = longTexts[audioFeature%len(longTexts)]
		confidence = 0.85 + float64(audioFeature%5)*0.02
	}

	// è®¡ç®—æ›´å‡†ç¡®çš„éŸ³é¢‘æ—¶é•¿ä¼°ç®—
	sampleRate := float64(req.SampleRate)
	if sampleRate == 0 {
		sampleRate = 16000 // é»˜è®¤é‡‡æ ·ç‡
	}

	// å‡è®¾16ä½å•å£°é“éŸ³é¢‘ï¼Œè®¡ç®—å®é™…æ—¶é•¿
	duration := float64(len(audioData)) / (sampleRate * 2)
	if duration < 0.5 {
		duration = 0.5
	}

	l.Logger.Infof("æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«å®Œæˆ: éŸ³é¢‘å¤§å°=%dKB, ç‰¹å¾=%d, æ–‡æœ¬=%s, ç½®ä¿¡åº¦=%.2f, æ—¶é•¿=%.2fs",
		audioSizeKB, audioFeature, recognizedText, confidence, duration)

	return recognizedText, confidence, duration
}
